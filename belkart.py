# belkart_parser.py
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from dotenv import load_dotenv
from collections import defaultdict
from typing import List, Dict, Any, Optional, Callable, Tuple

from db_sql import save_single_category, save_partners_with_status_logic

ProgressFn = Optional[Callable[[int, int, str], None]]

BASE_URL = "https://belkart.by/BELKART/reklamnye-aktsii/"

from gigachat import GigaChat
import json
import os

load_dotenv()

GIGACHAT_TOKEN = os.getenv("GIGACHAT_TOKEN")

gc = GigaChat(
    credentials=GIGACHAT_TOKEN,
    scope="GIGACHAT_API_B2B",
    verify_ssl_certs=False,
    model="GigaChat-2-Max",
)
print("GIGACHAT_TOKEN =", GIGACHAT_TOKEN)

_GIGA_CACHE: Dict[str, Dict[str, Any]] = {}


def _parse_page(url: str) -> Tuple[List[Dict[str, Any]], BeautifulSoup]:
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ —Å —Å—Å—ã–ª–∫–∞–º–∏"""
    resp = requests.get(url, timeout=20)
    resp.raise_for_status()
    soup = BeautifulSoup(resp.text, "lxml")

    cards = soup.select("ul.card-list li.card-list__item")
    results = []
    
    print(f"üîç –ü–∞—Ä—Å–∏–º {len(cards)} –∫–∞—Ä—Ç–æ—á–µ–∫...")

    for i, card in enumerate(cards):
        link_tag = card.select_one("a.card-list__link")
        title_tag = card.select_one(".card-list__title")
        status_tag = card.select_one(".card-list__label")

        raw_title = title_tag.text.strip() if title_tag else ""
        raw_status = status_tag.text.strip() if status_tag else ""
        raw_link = urljoin(BASE_URL, link_tag["href"]) if link_tag and link_tag.get("href") else ""
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è GigaChat
        raw_text = f"{raw_title} {raw_status}".strip()
        
        print(f"  {i+1}. '{raw_title}' | —Å—Ç–∞—Ç—É—Å: '{raw_status}'")

        if raw_text in _GIGA_CACHE:
            nlp = _GIGA_CACHE[raw_text]
            print(f"    ‚ôªÔ∏è Cache: {nlp}")
        else:
            nlp = extract_company_and_bonus(raw_text)
            _GIGA_CACHE[raw_text] = nlp
            print(f"    üß† GigaChat: {nlp}")

        company = nlp.get("company") or raw_title
        bonus = nlp.get("bonus")
        
        company = company.strip()
        
        results.append({
            "title": raw_title,
            "link": raw_link,  
            "status": raw_status,
            "company": company,
            "bonus": bonus,
        })

    return results, soup


def extract_company_and_bonus(text: str) -> dict:
    if not text.strip():
        return {"company": None, "bonus": None}

    prompt = f"""
        –ò–∑–≤–ª–µ–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏ –∏ —Ä–∞–∑–º–µ—Ä –±–æ–Ω—É—Å–∞.
        –ï—Å–ª–∏ –±–æ–Ω—É—Å —É–∫–∞–∑–∞–Ω –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö (—Å–∫–∏–¥–∫–∞ 15%, 15%, -15%, –∫–µ—à–±—ç–∫ 20%, 2 –∫–Ω–∏–≥–∏ –≤ –ø–æ–¥–∞—Ä–æ–∫), –≤–µ—Ä–Ω–∏ –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å.

        –¢–µ–∫—Å—Ç:
        \"\"\"{text}\"\"\"

        –í–µ—Ä–Ω–∏ –°–¢–†–û–ì–û JSON –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π:
        {{
        "company": "...",
        "bonus": "..."
        }}

        –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π null.
        """

    try:
        resp = gc.chat(prompt)
        raw = resp.choices[0].message.content.strip()


        raw = raw.replace("```json", "").replace("```", "").strip()
        data = json.loads(raw)

        company = data.get("company")
        bonus = data.get("bonus")
        

        if bonus:
            bonus = str(bonus).strip()
            bonus = " ".join(bonus.split())

        return {
            "company": company,
            "bonus": bonus if bonus else None,
        }

    except Exception as e:
        print(f"‚ö†Ô∏è GigaChat error: {e}")
        return {
            "company": None,
            "bonus": None,
        }


def save_belkart_items(bank_id: int, items: list):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –ë–µ–ª–∫–∞—Ä—Ç, –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—è:
    1. –í—Å–µ –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ 0
    2. –ù–µ—Ç –¥—É–±–ª–µ–π –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏
    3. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π/–ª—É—á—à–∏–π –±–æ–Ω—É—Å –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–º–ø–∞–Ω–∏–∏
    4. –°—Å—ã–ª–∫–∏ –≤—Å–µ–≥–¥–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã
    """
    if not items:
        print("‚ö†Ô∏è –ù–µ—Ç –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
        return

    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–æ–º–ø–∞–Ω–∏–∏: –∫–æ–º–ø–∞–Ω–∏—è ‚Üí —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–±–æ–Ω—É—Å, —Å—Å—ã–ª–∫–∞)
    grouped = defaultdict(list)
    
    for item in items:
        company = (item.get("company") or item.get("title") or "").strip()
        
        if not company:
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Ç–Ω—ë—Ä–∞ –±–µ–∑ –Ω–∞–∑–≤–∞–Ω–∏—è: {item}")
            continue
        
        bonus = item.get("bonus")
        link = item.get("link") or ""
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –±–æ–Ω—É—Å
        if bonus:
            bonus = str(bonus).strip()
            bonus = " ".join(bonus.split())  # —É–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        
        grouped[company].append({
            "bonus": bonus,
            "link": link,
        })

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫ –±–µ–∑ –¥—É–±–ª–µ–π
    partners_data = []
    
    for company, records in grouped.items():
        best_record = records[0] if records else None  
        best_bonus_value = -1
        
        if not best_record:
            print(f"‚ö†Ô∏è –ù–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è {company}")
            continue
        
        for rec in records:
            bonus = rec.get("bonus")
            link = rec.get("link")
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –±–æ–Ω—É—Å (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–æ–∫ –æ—Ç GigaChat)
            if isinstance(bonus, list):
                bonus = " ".join(str(b).strip() for b in bonus if b)
                rec["bonus"] = bonus if bonus else None
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –±–æ–Ω—É—Å–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            bonus_num = extract_bonus_number(bonus) if bonus else -1
            
            # –í—ã–±–∏—Ä–∞–µ–º –∑–∞–ø–∏—Å—å —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —á–∏—Å–ª–æ–≤—ã–º –±–æ–Ω—É—Å–æ–º
            if bonus_num > best_bonus_value or (bonus_num == best_bonus_value and link and not best_record.get("link")):
                best_bonus_value = bonus_num
                best_record = rec
        
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å—Å—ã–ª–∫–∏, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å—Ä–µ–¥–∏ –¥—É–±–ª–µ–π
        final_link = best_record.get("link") or ""
        if not final_link:
            for rec in records:
                if rec.get("link"):
                    final_link = rec.get("link")
                    break

        final_bonus = best_record.get("bonus")
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –±–æ–Ω—É—Å –µ—Å–ª–∏ —ç—Ç–æ —Å–ø–∏—Å–æ–∫
        if isinstance(final_bonus, list):
            final_bonus = " ".join(str(b).strip() for b in final_bonus if b) or None

        partners_data.append({
            "partner_name": company,
            "partner_bonus": final_bonus,
            "partner_link": final_link
        })
        
        print(f"  ‚úì {company} ‚Üí –±–æ–Ω—É—Å: {final_bonus or '–Ω–µ—Ç'}, —Å—Å—ã–ª–∫–∞: {'–¥–∞' if final_link else '–Ω–µ—Ç'}")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—é 0
    save_partners_with_status_logic(
        partners=partners_data,
        bank_id=bank_id,
        category_id=0
    )
    
    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(partners_data)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤ –ë–µ–ª–∫–∞—Ä—Ç")


def extract_bonus_number(bonus_str: Optional[str]) -> float:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –∏–∑–≤–ª–µ—á—å —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Å—Ç—Ä–æ–∫–∏ –±–æ–Ω—É—Å–∞.
    –ù–∞–ø—Ä–∏–º–µ—Ä: "—Å–∫–∏–¥–∫–∞ 15%" ‚Üí 15, "20 –¥–Ω–µ–π" ‚Üí 20, "2 –∫–Ω–∏–≥–∏ –≤ –ø–æ–¥–∞—Ä–æ–∫" ‚Üí 2
    """
    if not bonus_str:
        return -1
    
    import re
    
    # –ò—â–µ–º —á–∏—Å–ª–∞ –≤ —Å—Ç—Ä–æ–∫–µ
    numbers = re.findall(r'\d+(?:[\.,]\d+)?', str(bonus_str))
    
    if numbers:
        try:
            # –ë–µ—Ä—ë–º –ø–µ—Ä–≤–æ–µ —á–∏—Å–ª–æ
            return float(numbers[0].replace(',', '.'))
        except:
            return -1
    
    return -1


def fetch_promotions(
    bank_id: int,
    progress: ProgressFn = None,
    banks_done: int = 0,
    banks_total: int = 0,
) -> List[Dict[str, Any]]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ë–µ–ª–∫–∞—Ä—Ç–∞ –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ—Ö –ø–∞—Ä—Ç–Ω—ë—Ä–æ–≤.
    –ó–∞—Ç–µ–º —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏—Ö –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º.
    """
    all_items: List[Dict[str, Any]] = []
    page = 1

    while True:
        url = BASE_URL if page == 1 else f"{BASE_URL}?PAGEN_1={page}"
        note = f"[bank {bank_id}] üìÑ –ë–µ–ª–∫–∞—Ä—Ç ‚Äî —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page}"
        print(note)
        if progress:
            progress(banks_done, banks_total, note)

        try:
            items, soup = _parse_page(url)
        except Exception as e:
            err = f"[bank {bank_id}] ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page}: {e}"
            print(err)
            if progress:
                progress(banks_done, banks_total, err)
            break

        if not items:
            break

        all_items.extend(items)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
        next_page = soup.select_one(
            f'ul.pagination-list a.pagination-link[href*="PAGEN_1={page + 1}"]'
        )
        if not next_page:
            break

        page += 1

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –í–°–ï –ø–∞—Ä—Ç–Ω—ë—Ä—ã –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü
    if all_items:
        save_belkart_items(bank_id, all_items)
    
    done = f"[bank {bank_id}] ‚úÖ –ë–µ–ª–∫–∞—Ä—Ç ‚Äî –≤—Å–µ–≥–æ –∞–∫—Ü–∏–π: {len(all_items)}"
    print(done)
    if progress:
        progress(banks_done, banks_total, done)

    return all_items